{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6YDaWzqxWoSY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "n6rQ00BIXIM9",
    "outputId": "054b75e6-6550-468d-abed-b8e6605434da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.982788</td>\n",
       "      <td>0.636280</td>\n",
       "      <td>0.026205</td>\n",
       "      <td>-0.428302</td>\n",
       "      <td>0.806110</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>-0.201266</td>\n",
       "      <td>-0.300143</td>\n",
       "      <td>1.516755</td>\n",
       "      <td>-1.695836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384019</td>\n",
       "      <td>0.451372</td>\n",
       "      <td>0.143713</td>\n",
       "      <td>0.639740</td>\n",
       "      <td>1.180286</td>\n",
       "      <td>-0.398132</td>\n",
       "      <td>-0.734662</td>\n",
       "      <td>-1.755183</td>\n",
       "      <td>1.785207</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.308032</td>\n",
       "      <td>0.178448</td>\n",
       "      <td>-0.578047</td>\n",
       "      <td>0.626585</td>\n",
       "      <td>-0.399080</td>\n",
       "      <td>-0.137572</td>\n",
       "      <td>-0.427407</td>\n",
       "      <td>0.737020</td>\n",
       "      <td>0.634622</td>\n",
       "      <td>1.077456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.202575</td>\n",
       "      <td>0.852453</td>\n",
       "      <td>-0.781315</td>\n",
       "      <td>-1.706979</td>\n",
       "      <td>0.431412</td>\n",
       "      <td>0.679543</td>\n",
       "      <td>0.179937</td>\n",
       "      <td>1.562960</td>\n",
       "      <td>1.246345</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.036312</td>\n",
       "      <td>-0.618237</td>\n",
       "      <td>0.757178</td>\n",
       "      <td>0.199037</td>\n",
       "      <td>-1.895047</td>\n",
       "      <td>1.105581</td>\n",
       "      <td>-0.267929</td>\n",
       "      <td>-0.452879</td>\n",
       "      <td>-0.038079</td>\n",
       "      <td>-1.298838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.835760</td>\n",
       "      <td>2.246387</td>\n",
       "      <td>-0.999044</td>\n",
       "      <td>0.241686</td>\n",
       "      <td>1.946924</td>\n",
       "      <td>-0.055742</td>\n",
       "      <td>-0.247282</td>\n",
       "      <td>1.241116</td>\n",
       "      <td>0.797510</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.593587</td>\n",
       "      <td>0.111944</td>\n",
       "      <td>1.032377</td>\n",
       "      <td>1.098603</td>\n",
       "      <td>-0.897947</td>\n",
       "      <td>-1.040369</td>\n",
       "      <td>1.022640</td>\n",
       "      <td>-1.185127</td>\n",
       "      <td>-1.237272</td>\n",
       "      <td>-1.624552</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.391719</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>-0.637234</td>\n",
       "      <td>-0.395446</td>\n",
       "      <td>1.167238</td>\n",
       "      <td>-1.146398</td>\n",
       "      <td>0.504509</td>\n",
       "      <td>-1.403000</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.736228</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>-1.717402</td>\n",
       "      <td>1.079271</td>\n",
       "      <td>-0.367102</td>\n",
       "      <td>-1.474535</td>\n",
       "      <td>-0.164572</td>\n",
       "      <td>0.317099</td>\n",
       "      <td>-0.656236</td>\n",
       "      <td>1.037916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.641369</td>\n",
       "      <td>0.269537</td>\n",
       "      <td>-0.918724</td>\n",
       "      <td>1.950812</td>\n",
       "      <td>-1.488772</td>\n",
       "      <td>-1.730112</td>\n",
       "      <td>-1.159047</td>\n",
       "      <td>-0.537253</td>\n",
       "      <td>1.700184</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>-0.842281</td>\n",
       "      <td>0.289164</td>\n",
       "      <td>0.404224</td>\n",
       "      <td>-0.588546</td>\n",
       "      <td>0.497505</td>\n",
       "      <td>-1.841256</td>\n",
       "      <td>0.768579</td>\n",
       "      <td>0.242663</td>\n",
       "      <td>-1.129596</td>\n",
       "      <td>-0.353730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123436</td>\n",
       "      <td>0.235004</td>\n",
       "      <td>-0.730740</td>\n",
       "      <td>1.318898</td>\n",
       "      <td>-0.117078</td>\n",
       "      <td>-0.380366</td>\n",
       "      <td>1.444778</td>\n",
       "      <td>0.380130</td>\n",
       "      <td>1.716711</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>-0.814783</td>\n",
       "      <td>0.903289</td>\n",
       "      <td>-0.649079</td>\n",
       "      <td>0.558818</td>\n",
       "      <td>0.581950</td>\n",
       "      <td>-1.087061</td>\n",
       "      <td>1.973154</td>\n",
       "      <td>0.881107</td>\n",
       "      <td>-1.676159</td>\n",
       "      <td>0.519693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965649</td>\n",
       "      <td>1.686916</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.193365</td>\n",
       "      <td>-0.781087</td>\n",
       "      <td>0.599595</td>\n",
       "      <td>1.416381</td>\n",
       "      <td>0.227833</td>\n",
       "      <td>-0.548911</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>1.652728</td>\n",
       "      <td>0.941576</td>\n",
       "      <td>-0.791736</td>\n",
       "      <td>0.359181</td>\n",
       "      <td>-0.238372</td>\n",
       "      <td>0.854603</td>\n",
       "      <td>0.298399</td>\n",
       "      <td>-0.103699</td>\n",
       "      <td>1.117458</td>\n",
       "      <td>2.126494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129304</td>\n",
       "      <td>0.222394</td>\n",
       "      <td>1.293075</td>\n",
       "      <td>1.427311</td>\n",
       "      <td>1.066479</td>\n",
       "      <td>1.203590</td>\n",
       "      <td>-0.287603</td>\n",
       "      <td>0.341568</td>\n",
       "      <td>0.421119</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>-0.343395</td>\n",
       "      <td>-1.077136</td>\n",
       "      <td>0.081769</td>\n",
       "      <td>-0.961482</td>\n",
       "      <td>-0.401869</td>\n",
       "      <td>0.253316</td>\n",
       "      <td>0.559567</td>\n",
       "      <td>2.216032</td>\n",
       "      <td>-1.036015</td>\n",
       "      <td>-0.253903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321489</td>\n",
       "      <td>-0.502074</td>\n",
       "      <td>0.503779</td>\n",
       "      <td>0.395119</td>\n",
       "      <td>1.464168</td>\n",
       "      <td>1.493723</td>\n",
       "      <td>-1.525271</td>\n",
       "      <td>0.887973</td>\n",
       "      <td>1.123517</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>-2.153147</td>\n",
       "      <td>-0.709350</td>\n",
       "      <td>2.216687</td>\n",
       "      <td>2.498179</td>\n",
       "      <td>-0.756145</td>\n",
       "      <td>1.865583</td>\n",
       "      <td>-1.800357</td>\n",
       "      <td>1.604506</td>\n",
       "      <td>-0.037380</td>\n",
       "      <td>1.872088</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.920961</td>\n",
       "      <td>-2.165179</td>\n",
       "      <td>1.993132</td>\n",
       "      <td>-1.255477</td>\n",
       "      <td>-3.588995</td>\n",
       "      <td>4.193891</td>\n",
       "      <td>2.892434</td>\n",
       "      <td>1.188468</td>\n",
       "      <td>-4.179591</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4993 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     1.982788  0.636280  0.026205 -0.428302  0.806110  0.888753 -0.201266   \n",
       "1    -0.308032  0.178448 -0.578047  0.626585 -0.399080 -0.137572 -0.427407   \n",
       "2     1.036312 -0.618237  0.757178  0.199037 -1.895047  1.105581 -0.267929   \n",
       "3    -0.593587  0.111944  1.032377  1.098603 -0.897947 -1.040369  1.022640   \n",
       "4    -0.736228  0.762001 -1.717402  1.079271 -0.367102 -1.474535 -0.164572   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4988 -0.842281  0.289164  0.404224 -0.588546  0.497505 -1.841256  0.768579   \n",
       "4989 -0.814783  0.903289 -0.649079  0.558818  0.581950 -1.087061  1.973154   \n",
       "4990  1.652728  0.941576 -0.791736  0.359181 -0.238372  0.854603  0.298399   \n",
       "4991 -0.343395 -1.077136  0.081769 -0.961482 -0.401869  0.253316  0.559567   \n",
       "4992 -2.153147 -0.709350  2.216687  2.498179 -0.756145  1.865583 -1.800357   \n",
       "\n",
       "             7         8         9  ...       759       760       761  \\\n",
       "0    -0.300143  1.516755 -1.695836  ... -0.384019  0.451372  0.143713   \n",
       "1     0.737020  0.634622  1.077456  ...  1.202575  0.852453 -0.781315   \n",
       "2    -0.452879 -0.038079 -1.298838  ... -0.835760  2.246387 -0.999044   \n",
       "3    -1.185127 -1.237272 -1.624552  ... -1.391719  0.759933 -0.637234   \n",
       "4     0.317099 -0.656236  1.037916  ... -0.641369  0.269537 -0.918724   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4988  0.242663 -1.129596 -0.353730  ...  0.123436  0.235004 -0.730740   \n",
       "4989  0.881107 -1.676159  0.519693  ...  0.965649  1.686916  0.233233   \n",
       "4990 -0.103699  1.117458  2.126494  ...  0.129304  0.222394  1.293075   \n",
       "4991  2.216032 -1.036015 -0.253903  ...  0.321489 -0.502074  0.503779   \n",
       "4992  1.604506 -0.037380  1.872088  ... -3.920961 -2.165179  1.993132   \n",
       "\n",
       "           762       763       764       765       766       767       tag  \n",
       "0     0.639740  1.180286 -0.398132 -0.734662 -1.755183  1.785207   society  \n",
       "1    -1.706979  0.431412  0.679543  0.179937  1.562960  1.246345   society  \n",
       "2     0.241686  1.946924 -0.055742 -0.247282  1.241116  0.797510   society  \n",
       "3    -0.395446  1.167238 -1.146398  0.504509 -1.403000  0.008811   society  \n",
       "4     1.950812 -1.488772 -1.730112 -1.159047 -0.537253  1.700184   society  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4988  1.318898 -0.117078 -0.380366  1.444778  0.380130  1.716711  politics  \n",
       "4989  0.193365 -0.781087  0.599595  1.416381  0.227833 -0.548911   society  \n",
       "4990  1.427311  1.066479  1.203590 -0.287603  0.341568  0.421119   society  \n",
       "4991  0.395119  1.464168  1.493723 -1.525271  0.887973  1.123517   science  \n",
       "4992 -1.255477 -3.588995  4.193891  2.892434  1.188468 -4.179591   society  \n",
       "\n",
       "[4993 rows x 769 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_titles = pd.read_csv(\"titles_bert.csv\", sep=';', index_col=0)\n",
    "scaled_data_titles = pd.DataFrame(data=StandardScaler().fit_transform(data_titles.drop('tag', axis='columns')),\n",
    "                                  columns=data_titles.drop('tag', axis='columns').columns)\n",
    "scaled_data_titles['tag'] = data_titles['tag']\n",
    "scaled_data_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "D7QeOpv8X9Hi",
    "outputId": "00e206e7-ca3d-4b2c-9b80-0a729d88d7ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.835533</td>\n",
       "      <td>1.376226</td>\n",
       "      <td>2.992430</td>\n",
       "      <td>0.101940</td>\n",
       "      <td>-1.560078</td>\n",
       "      <td>-0.084151</td>\n",
       "      <td>0.984520</td>\n",
       "      <td>-2.708209</td>\n",
       "      <td>1.797536</td>\n",
       "      <td>0.690925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442746</td>\n",
       "      <td>-0.848235</td>\n",
       "      <td>-0.898623</td>\n",
       "      <td>0.116909</td>\n",
       "      <td>1.327458</td>\n",
       "      <td>-1.735393</td>\n",
       "      <td>1.354291</td>\n",
       "      <td>-0.653356</td>\n",
       "      <td>-0.849807</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.861976</td>\n",
       "      <td>0.432571</td>\n",
       "      <td>-0.423595</td>\n",
       "      <td>-0.825834</td>\n",
       "      <td>0.508335</td>\n",
       "      <td>1.655087</td>\n",
       "      <td>-0.374494</td>\n",
       "      <td>-2.021640</td>\n",
       "      <td>0.569279</td>\n",
       "      <td>0.298125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.540152</td>\n",
       "      <td>1.072514</td>\n",
       "      <td>-0.768824</td>\n",
       "      <td>-0.287196</td>\n",
       "      <td>-0.153840</td>\n",
       "      <td>-0.046399</td>\n",
       "      <td>-0.225241</td>\n",
       "      <td>-1.406981</td>\n",
       "      <td>-1.307059</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506031</td>\n",
       "      <td>1.236236</td>\n",
       "      <td>-1.392696</td>\n",
       "      <td>0.737111</td>\n",
       "      <td>1.641614</td>\n",
       "      <td>-0.780017</td>\n",
       "      <td>-0.627772</td>\n",
       "      <td>-1.115202</td>\n",
       "      <td>1.615938</td>\n",
       "      <td>-0.574158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701086</td>\n",
       "      <td>1.249610</td>\n",
       "      <td>1.859676</td>\n",
       "      <td>-0.953304</td>\n",
       "      <td>-0.232084</td>\n",
       "      <td>-0.815959</td>\n",
       "      <td>-2.889244</td>\n",
       "      <td>0.669419</td>\n",
       "      <td>1.163325</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.434785</td>\n",
       "      <td>-0.851983</td>\n",
       "      <td>-0.677896</td>\n",
       "      <td>-1.619145</td>\n",
       "      <td>0.995476</td>\n",
       "      <td>0.820249</td>\n",
       "      <td>-0.594013</td>\n",
       "      <td>0.198919</td>\n",
       "      <td>0.801927</td>\n",
       "      <td>1.718985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>-0.194544</td>\n",
       "      <td>-0.749033</td>\n",
       "      <td>-0.598448</td>\n",
       "      <td>0.075641</td>\n",
       "      <td>0.350724</td>\n",
       "      <td>-0.852142</td>\n",
       "      <td>0.327182</td>\n",
       "      <td>0.480588</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287372</td>\n",
       "      <td>0.493638</td>\n",
       "      <td>0.352622</td>\n",
       "      <td>1.077253</td>\n",
       "      <td>-0.140485</td>\n",
       "      <td>-0.501860</td>\n",
       "      <td>0.450711</td>\n",
       "      <td>-0.390699</td>\n",
       "      <td>0.920146</td>\n",
       "      <td>1.526652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083041</td>\n",
       "      <td>1.456687</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.350316</td>\n",
       "      <td>-1.160809</td>\n",
       "      <td>-0.667480</td>\n",
       "      <td>-0.959954</td>\n",
       "      <td>0.791802</td>\n",
       "      <td>-0.572998</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>1.717120</td>\n",
       "      <td>1.008547</td>\n",
       "      <td>0.342709</td>\n",
       "      <td>-1.318128</td>\n",
       "      <td>-0.329470</td>\n",
       "      <td>1.016126</td>\n",
       "      <td>-0.165130</td>\n",
       "      <td>-0.755877</td>\n",
       "      <td>-0.461993</td>\n",
       "      <td>-1.174749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066041</td>\n",
       "      <td>2.050252</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>-0.161464</td>\n",
       "      <td>1.291077</td>\n",
       "      <td>-0.485754</td>\n",
       "      <td>-0.440894</td>\n",
       "      <td>0.465067</td>\n",
       "      <td>-0.207532</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>-0.999162</td>\n",
       "      <td>-0.686018</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>-0.547198</td>\n",
       "      <td>-0.460379</td>\n",
       "      <td>-1.151463</td>\n",
       "      <td>-0.203387</td>\n",
       "      <td>0.443674</td>\n",
       "      <td>-1.558448</td>\n",
       "      <td>-1.492466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243955</td>\n",
       "      <td>-1.069245</td>\n",
       "      <td>0.360546</td>\n",
       "      <td>1.479754</td>\n",
       "      <td>0.086263</td>\n",
       "      <td>-1.006575</td>\n",
       "      <td>0.919041</td>\n",
       "      <td>-0.183685</td>\n",
       "      <td>-0.740854</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>-0.167977</td>\n",
       "      <td>0.475681</td>\n",
       "      <td>0.611242</td>\n",
       "      <td>0.041531</td>\n",
       "      <td>-1.619936</td>\n",
       "      <td>0.484497</td>\n",
       "      <td>0.760639</td>\n",
       "      <td>1.080717</td>\n",
       "      <td>-1.764248</td>\n",
       "      <td>-0.472329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487375</td>\n",
       "      <td>0.597081</td>\n",
       "      <td>-0.013648</td>\n",
       "      <td>-0.709787</td>\n",
       "      <td>-0.301182</td>\n",
       "      <td>0.131828</td>\n",
       "      <td>0.539551</td>\n",
       "      <td>0.702470</td>\n",
       "      <td>-0.388982</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>-1.577400</td>\n",
       "      <td>0.514657</td>\n",
       "      <td>0.281482</td>\n",
       "      <td>0.618723</td>\n",
       "      <td>-0.428352</td>\n",
       "      <td>-1.068472</td>\n",
       "      <td>0.721227</td>\n",
       "      <td>0.323401</td>\n",
       "      <td>-1.695198</td>\n",
       "      <td>-0.797388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.524988</td>\n",
       "      <td>0.717161</td>\n",
       "      <td>-0.267880</td>\n",
       "      <td>0.783461</td>\n",
       "      <td>0.940894</td>\n",
       "      <td>0.131928</td>\n",
       "      <td>1.141258</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>-0.377740</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>-1.931435</td>\n",
       "      <td>2.657621</td>\n",
       "      <td>3.352658</td>\n",
       "      <td>-0.579691</td>\n",
       "      <td>1.006930</td>\n",
       "      <td>4.381178</td>\n",
       "      <td>-3.881491</td>\n",
       "      <td>-0.093696</td>\n",
       "      <td>0.330440</td>\n",
       "      <td>4.848136</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.340299</td>\n",
       "      <td>-2.080389</td>\n",
       "      <td>-1.323755</td>\n",
       "      <td>-1.188662</td>\n",
       "      <td>-2.456257</td>\n",
       "      <td>3.012751</td>\n",
       "      <td>1.337304</td>\n",
       "      <td>-1.156579</td>\n",
       "      <td>-0.330319</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4993 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.835533  1.376226  2.992430  0.101940 -1.560078 -0.084151  0.984520   \n",
       "1     0.861976  0.432571 -0.423595 -0.825834  0.508335  1.655087 -0.374494   \n",
       "2     0.506031  1.236236 -1.392696  0.737111  1.641614 -0.780017 -0.627772   \n",
       "3     0.434785 -0.851983 -0.677896 -1.619145  0.995476  0.820249 -0.594013   \n",
       "4     0.287372  0.493638  0.352622  1.077253 -0.140485 -0.501860  0.450711   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4988  1.717120  1.008547  0.342709 -1.318128 -0.329470  1.016126 -0.165130   \n",
       "4989 -0.999162 -0.686018  0.999208 -0.547198 -0.460379 -1.151463 -0.203387   \n",
       "4990 -0.167977  0.475681  0.611242  0.041531 -1.619936  0.484497  0.760639   \n",
       "4991 -1.577400  0.514657  0.281482  0.618723 -0.428352 -1.068472  0.721227   \n",
       "4992 -1.931435  2.657621  3.352658 -0.579691  1.006930  4.381178 -3.881491   \n",
       "\n",
       "             7         8         9  ...       759       760       761  \\\n",
       "0    -2.708209  1.797536  0.690925  ... -0.442746 -0.848235 -0.898623   \n",
       "1    -2.021640  0.569279  0.298125  ... -0.540152  1.072514 -0.768824   \n",
       "2    -1.115202  1.615938 -0.574158  ...  0.701086  1.249610  1.859676   \n",
       "3     0.198919  0.801927  1.718985  ...  0.006928 -0.194544 -0.749033   \n",
       "4    -0.390699  0.920146  1.526652  ...  0.083041  1.456687  0.285124   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4988 -0.755877 -0.461993 -1.174749  ...  0.066041  2.050252  0.018005   \n",
       "4989  0.443674 -1.558448 -1.492466  ...  0.243955 -1.069245  0.360546   \n",
       "4990  1.080717 -1.764248 -0.472329  ... -0.487375  0.597081 -0.013648   \n",
       "4991  0.323401 -1.695198 -0.797388  ... -0.524988  0.717161 -0.267880   \n",
       "4992 -0.093696  0.330440  4.848136  ... -2.340299 -2.080389 -1.323755   \n",
       "\n",
       "           762       763       764       765       766       767       tag  \n",
       "0     0.116909  1.327458 -1.735393  1.354291 -0.653356 -0.849807   society  \n",
       "1    -0.287196 -0.153840 -0.046399 -0.225241 -1.406981 -1.307059   society  \n",
       "2    -0.953304 -0.232084 -0.815959 -2.889244  0.669419  1.163325   society  \n",
       "3    -0.598448  0.075641  0.350724 -0.852142  0.327182  0.480588   society  \n",
       "4     0.350316 -1.160809 -0.667480 -0.959954  0.791802 -0.572998   society  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4988 -0.161464  1.291077 -0.485754 -0.440894  0.465067 -0.207532  politics  \n",
       "4989  1.479754  0.086263 -1.006575  0.919041 -0.183685 -0.740854   society  \n",
       "4990 -0.709787 -0.301182  0.131828  0.539551  0.702470 -0.388982   society  \n",
       "4991  0.783461  0.940894  0.131928  1.141258  0.760456 -0.377740   science  \n",
       "4992 -1.188662 -2.456257  3.012751  1.337304 -1.156579 -0.330319   society  \n",
       "\n",
       "[4993 rows x 769 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_texts = pd.read_csv(\"texts_bert.csv\", sep=';', index_col=0)\n",
    "scaled_data_texts = pd.DataFrame(data=StandardScaler().fit_transform(data_texts.drop('tag', axis='columns')),\n",
    "                                  columns=data_texts.drop('tag', axis='columns').columns)\n",
    "scaled_data_texts['tag'] = data_texts['tag']\n",
    "scaled_data_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7J8WJ-45YECK"
   },
   "outputs": [],
   "source": [
    "def encode_tag(data):\n",
    "    dic = {\n",
    "        'society': 0,\n",
    "        'politics': 1,\n",
    "        'economics': 2,\n",
    "        'science': 3,\n",
    "        'books': 4\n",
    "    }\n",
    "    new_tags = []\n",
    "    for tag in data['tag']:\n",
    "        new_tags.append(dic[tag])\n",
    "    data['tag'] = new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C1SwTNm4Y2_1"
   },
   "outputs": [],
   "source": [
    "encode_tag(scaled_data_titles)\n",
    "encode_tag(scaled_data_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "EeQYvR2zY73j",
    "outputId": "4eadb6c7-b7eb-4a83-f7f0-cf2e810d36aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.982788</td>\n",
       "      <td>0.636280</td>\n",
       "      <td>0.026205</td>\n",
       "      <td>-0.428302</td>\n",
       "      <td>0.806110</td>\n",
       "      <td>0.888753</td>\n",
       "      <td>-0.201266</td>\n",
       "      <td>-0.300143</td>\n",
       "      <td>1.516755</td>\n",
       "      <td>-1.695836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384019</td>\n",
       "      <td>0.451372</td>\n",
       "      <td>0.143713</td>\n",
       "      <td>0.639740</td>\n",
       "      <td>1.180286</td>\n",
       "      <td>-0.398132</td>\n",
       "      <td>-0.734662</td>\n",
       "      <td>-1.755183</td>\n",
       "      <td>1.785207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.308032</td>\n",
       "      <td>0.178448</td>\n",
       "      <td>-0.578047</td>\n",
       "      <td>0.626585</td>\n",
       "      <td>-0.399080</td>\n",
       "      <td>-0.137572</td>\n",
       "      <td>-0.427407</td>\n",
       "      <td>0.737020</td>\n",
       "      <td>0.634622</td>\n",
       "      <td>1.077456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.202575</td>\n",
       "      <td>0.852453</td>\n",
       "      <td>-0.781315</td>\n",
       "      <td>-1.706979</td>\n",
       "      <td>0.431412</td>\n",
       "      <td>0.679543</td>\n",
       "      <td>0.179937</td>\n",
       "      <td>1.562960</td>\n",
       "      <td>1.246345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.036312</td>\n",
       "      <td>-0.618237</td>\n",
       "      <td>0.757178</td>\n",
       "      <td>0.199037</td>\n",
       "      <td>-1.895047</td>\n",
       "      <td>1.105581</td>\n",
       "      <td>-0.267929</td>\n",
       "      <td>-0.452879</td>\n",
       "      <td>-0.038079</td>\n",
       "      <td>-1.298838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.835760</td>\n",
       "      <td>2.246387</td>\n",
       "      <td>-0.999044</td>\n",
       "      <td>0.241686</td>\n",
       "      <td>1.946924</td>\n",
       "      <td>-0.055742</td>\n",
       "      <td>-0.247282</td>\n",
       "      <td>1.241116</td>\n",
       "      <td>0.797510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.593587</td>\n",
       "      <td>0.111944</td>\n",
       "      <td>1.032377</td>\n",
       "      <td>1.098603</td>\n",
       "      <td>-0.897947</td>\n",
       "      <td>-1.040369</td>\n",
       "      <td>1.022640</td>\n",
       "      <td>-1.185127</td>\n",
       "      <td>-1.237272</td>\n",
       "      <td>-1.624552</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.391719</td>\n",
       "      <td>0.759933</td>\n",
       "      <td>-0.637234</td>\n",
       "      <td>-0.395446</td>\n",
       "      <td>1.167238</td>\n",
       "      <td>-1.146398</td>\n",
       "      <td>0.504509</td>\n",
       "      <td>-1.403000</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.736228</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>-1.717402</td>\n",
       "      <td>1.079271</td>\n",
       "      <td>-0.367102</td>\n",
       "      <td>-1.474535</td>\n",
       "      <td>-0.164572</td>\n",
       "      <td>0.317099</td>\n",
       "      <td>-0.656236</td>\n",
       "      <td>1.037916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.641369</td>\n",
       "      <td>0.269537</td>\n",
       "      <td>-0.918724</td>\n",
       "      <td>1.950812</td>\n",
       "      <td>-1.488772</td>\n",
       "      <td>-1.730112</td>\n",
       "      <td>-1.159047</td>\n",
       "      <td>-0.537253</td>\n",
       "      <td>1.700184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.224977</td>\n",
       "      <td>1.693298</td>\n",
       "      <td>0.473479</td>\n",
       "      <td>-0.954427</td>\n",
       "      <td>0.377010</td>\n",
       "      <td>-1.578833</td>\n",
       "      <td>2.125805</td>\n",
       "      <td>-3.194222</td>\n",
       "      <td>0.424827</td>\n",
       "      <td>-0.975309</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.356036</td>\n",
       "      <td>-0.708303</td>\n",
       "      <td>-1.371023</td>\n",
       "      <td>0.028115</td>\n",
       "      <td>-0.036139</td>\n",
       "      <td>0.108983</td>\n",
       "      <td>0.231719</td>\n",
       "      <td>-0.189435</td>\n",
       "      <td>-1.702182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.574279</td>\n",
       "      <td>-0.379246</td>\n",
       "      <td>0.565063</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>-0.538655</td>\n",
       "      <td>-0.409614</td>\n",
       "      <td>-1.290103</td>\n",
       "      <td>1.963522</td>\n",
       "      <td>-0.471619</td>\n",
       "      <td>-0.451271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571814</td>\n",
       "      <td>2.130367</td>\n",
       "      <td>0.379167</td>\n",
       "      <td>-1.005335</td>\n",
       "      <td>1.584527</td>\n",
       "      <td>-0.998510</td>\n",
       "      <td>-0.297637</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>2.185497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.745556</td>\n",
       "      <td>1.381918</td>\n",
       "      <td>-1.321507</td>\n",
       "      <td>2.028954</td>\n",
       "      <td>0.797043</td>\n",
       "      <td>0.502394</td>\n",
       "      <td>-0.935365</td>\n",
       "      <td>2.779975</td>\n",
       "      <td>0.156413</td>\n",
       "      <td>0.634446</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.006352</td>\n",
       "      <td>0.387942</td>\n",
       "      <td>-0.069132</td>\n",
       "      <td>0.974073</td>\n",
       "      <td>-0.769685</td>\n",
       "      <td>-2.206356</td>\n",
       "      <td>-1.088934</td>\n",
       "      <td>0.563868</td>\n",
       "      <td>0.053441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.219547</td>\n",
       "      <td>-0.107227</td>\n",
       "      <td>-0.183340</td>\n",
       "      <td>0.736846</td>\n",
       "      <td>-0.986749</td>\n",
       "      <td>-0.181782</td>\n",
       "      <td>-1.475464</td>\n",
       "      <td>-0.246313</td>\n",
       "      <td>0.413363</td>\n",
       "      <td>-0.110747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319769</td>\n",
       "      <td>0.895669</td>\n",
       "      <td>1.007312</td>\n",
       "      <td>0.157346</td>\n",
       "      <td>0.592778</td>\n",
       "      <td>0.171054</td>\n",
       "      <td>-1.016979</td>\n",
       "      <td>0.462089</td>\n",
       "      <td>0.266908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.765229</td>\n",
       "      <td>0.537559</td>\n",
       "      <td>0.568720</td>\n",
       "      <td>-0.384725</td>\n",
       "      <td>0.776401</td>\n",
       "      <td>1.380154</td>\n",
       "      <td>1.650151</td>\n",
       "      <td>-0.125340</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.057383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211182</td>\n",
       "      <td>-0.505680</td>\n",
       "      <td>1.743330</td>\n",
       "      <td>-0.111853</td>\n",
       "      <td>0.921340</td>\n",
       "      <td>-0.324186</td>\n",
       "      <td>-0.861971</td>\n",
       "      <td>-0.511207</td>\n",
       "      <td>0.699923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.982788  0.636280  0.026205 -0.428302  0.806110  0.888753 -0.201266   \n",
       "1 -0.308032  0.178448 -0.578047  0.626585 -0.399080 -0.137572 -0.427407   \n",
       "2  1.036312 -0.618237  0.757178  0.199037 -1.895047  1.105581 -0.267929   \n",
       "3 -0.593587  0.111944  1.032377  1.098603 -0.897947 -1.040369  1.022640   \n",
       "4 -0.736228  0.762001 -1.717402  1.079271 -0.367102 -1.474535 -0.164572   \n",
       "5 -0.224977  1.693298  0.473479 -0.954427  0.377010 -1.578833  2.125805   \n",
       "6  1.574279 -0.379246  0.565063  0.086522 -0.538655 -0.409614 -1.290103   \n",
       "7 -0.745556  1.381918 -1.321507  2.028954  0.797043  0.502394 -0.935365   \n",
       "8 -0.219547 -0.107227 -0.183340  0.736846 -0.986749 -0.181782 -1.475464   \n",
       "9 -0.765229  0.537559  0.568720 -0.384725  0.776401  1.380154  1.650151   \n",
       "\n",
       "          7         8         9  ...       759       760       761       762  \\\n",
       "0 -0.300143  1.516755 -1.695836  ... -0.384019  0.451372  0.143713  0.639740   \n",
       "1  0.737020  0.634622  1.077456  ...  1.202575  0.852453 -0.781315 -1.706979   \n",
       "2 -0.452879 -0.038079 -1.298838  ... -0.835760  2.246387 -0.999044  0.241686   \n",
       "3 -1.185127 -1.237272 -1.624552  ... -1.391719  0.759933 -0.637234 -0.395446   \n",
       "4  0.317099 -0.656236  1.037916  ... -0.641369  0.269537 -0.918724  1.950812   \n",
       "5 -3.194222  0.424827 -0.975309  ... -1.356036 -0.708303 -1.371023  0.028115   \n",
       "6  1.963522 -0.471619 -0.451271  ...  0.571814  2.130367  0.379167 -1.005335   \n",
       "7  2.779975  0.156413  0.634446  ... -1.006352  0.387942 -0.069132  0.974073   \n",
       "8 -0.246313  0.413363 -0.110747  ...  0.319769  0.895669  1.007312  0.157346   \n",
       "9 -0.125340  0.491573  0.057383  ... -0.211182 -0.505680  1.743330 -0.111853   \n",
       "\n",
       "        763       764       765       766       767  tag  \n",
       "0  1.180286 -0.398132 -0.734662 -1.755183  1.785207    0  \n",
       "1  0.431412  0.679543  0.179937  1.562960  1.246345    0  \n",
       "2  1.946924 -0.055742 -0.247282  1.241116  0.797510    0  \n",
       "3  1.167238 -1.146398  0.504509 -1.403000  0.008811    0  \n",
       "4 -1.488772 -1.730112 -1.159047 -0.537253  1.700184    0  \n",
       "5 -0.036139  0.108983  0.231719 -0.189435 -1.702182    1  \n",
       "6  1.584527 -0.998510 -0.297637  0.429823  2.185497    1  \n",
       "7 -0.769685 -2.206356 -1.088934  0.563868  0.053441    1  \n",
       "8  0.592778  0.171054 -1.016979  0.462089  0.266908    0  \n",
       "9  0.921340 -0.324186 -0.861971 -0.511207  0.699923    1  \n",
       "\n",
       "[10 rows x 769 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data_titles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WlMv8Lg7ZaPV"
   },
   "outputs": [],
   "source": [
    "X, y = scaled_data_titles.drop('tag', axis = 'columns'), scaled_data_titles['tag']\n",
    "X_t, y_t = scaled_data_texts.drop('tag', axis = 'columns'), scaled_data_texts['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1C5rpgfrZXQq"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_t, y_t, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UUVrQlWZLYA"
   },
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U99REzqjZScU"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "Q2C3MwsiZUKE",
    "outputId": "a56b6149-4a82-4944-cec3-cbf539a825d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:  7.8min finished\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {'n_neighbors': range(10, 501, 10)}\n",
    "f1 = make_scorer(f1_score, average='weighted')  # for scoring param\n",
    "rand_knn = RandomizedSearchCV(estimator=KNeighborsClassifier(),\n",
    "                              param_distributions=param_distributions,\n",
    "                              cv=3,\n",
    "                              verbose=3,\n",
    "                              n_iter = 50,\n",
    "                              n_jobs=4,\n",
    "                              scoring=f1)\n",
    "rand_knn.fit(X_train, y_train)\n",
    "y_pred = rand_knn.predict(X_test)\n",
    "y_prob = rand_knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XdDYmVx1ZvMS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6293034427542034\n",
      "Recall: 0.6293034427542034\n",
      "Precision: 0.4824442837709277\n",
      "F1: 0.5163532957693111\n",
      "ROC AUC: 0.5215788338967055\n",
      "Confusion matrix:\n",
      " [[771  30   0   0   0]\n",
      " [302  15   0   0   0]\n",
      " [ 58   6   0   0   0]\n",
      " [ 60   5   0   0   0]\n",
      " [  2   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.96      0.77       801\n",
      "           1       0.27      0.05      0.08       317\n",
      "           2       0.00      0.00      0.00        64\n",
      "           3       0.00      0.00      0.00        65\n",
      "           4       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.63      1249\n",
      "   macro avg       0.18      0.20      0.17      1249\n",
      "weighted avg       0.48      0.63      0.52      1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob, average = 'weighted', multi_class='ovo'))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed: 14.5min finished\n"
     ]
    }
   ],
   "source": [
    "classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1))\n",
    "param_grid = {\n",
    "    'n_estimators': range(10, 301, 20),\n",
    "    'learning_rate': [0.1, 0.25, 0.5, 0.75, 1]\n",
    "}\n",
    "\n",
    "randdAdaBoost = RandomizedSearchCV(estimator=classifier,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   cv=2,\n",
    "                                   n_iter=50,\n",
    "                                   verbose=3,\n",
    "                                   scoring=f1,\n",
    "                                   n_jobs=4)\n",
    "\n",
    "randdAdaBoost.fit(X_train, y_train)\n",
    "y_pred = randdAdaBoost.predict(X_test)\n",
    "y_prob = randdAdaBoost.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6309047237790232\n",
      "Recall: 0.6309047237790232\n",
      "Precision: 0.4818294133337264\n",
      "F1: 0.5098530163339777\n",
      "ROC AUC: 0.5307793300137135\n",
      "Confusion matrix:\n",
      " [[778  23   0   0   0]\n",
      " [307  10   0   0   0]\n",
      " [ 63   1   0   0   0]\n",
      " [ 63   2   0   0   0]\n",
      " [  2   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77       801\n",
      "           1       0.28      0.03      0.06       317\n",
      "           2       0.00      0.00      0.00        64\n",
      "           3       0.00      0.00      0.00        65\n",
      "           4       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.63      1249\n",
      "   macro avg       0.18      0.20      0.17      1249\n",
      "weighted avg       0.48      0.63      0.51      1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob, average = 'weighted', multi_class='ovo'))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:  8.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:  8.3min finished\n"
     ]
    }
   ],
   "source": [
    "svcclassifier = SVC(probability=True)\n",
    "param_grid = {\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "    'C' : [0.1, 1, 10, 100, 1000],\n",
    "    'gamma' : [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'degree' : [2,3,4]\n",
    "}\n",
    "\n",
    "rand_svc = RandomizedSearchCV(estimator=svcclassifier,\n",
    "                              param_distributions=param_grid,\n",
    "                              scoring=f1,\n",
    "                              n_jobs=4,\n",
    "                              cv=2,\n",
    "                              verbose=3,\n",
    "                              refit=True)\n",
    "\n",
    "rand_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rand_svc.predict(X_test)\n",
    "y_proba = rand_svc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5804643714971978\n",
      "Recall: 0.5804643714971978\n",
      "Precision: 0.47505080093130203\n",
      "F1: 0.514246108799376\n",
      "ROC AUC: 0.5307793300137135\n",
      "Confusion matrix:\n",
      " [[681 112   5   3   0]\n",
      " [270  44   1   2   0]\n",
      " [ 56   8   0   0   0]\n",
      " [ 54  11   0   0   0]\n",
      " [  1   0   1   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73       801\n",
      "           1       0.25      0.14      0.18       317\n",
      "           2       0.00      0.00      0.00        64\n",
      "           3       0.00      0.00      0.00        65\n",
      "           4       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.58      1249\n",
      "   macro avg       0.18      0.20      0.18      1249\n",
      "weighted avg       0.48      0.58      0.51      1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob, average = 'weighted', multi_class='ovo'))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed: 28.0min finished\n"
     ]
    }
   ],
   "source": [
    "gbm = LGBMClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': range(10, 301, 20),\n",
    "    'learning_rate': [0.1, 0.25, 0.5, 0.75, 1]\n",
    "}\n",
    "randgbm = RandomizedSearchCV(estimator=gbm,\n",
    "                             param_distributions=param_grid,\n",
    "                             cv=2,\n",
    "                             verbose=3,\n",
    "                             n_iter=50,\n",
    "                             scoring=f1,\n",
    "                             n_jobs=4)\n",
    "randgbm.fit(X_train, y_train)\n",
    "y_pred = randgbm.predict(X_test)\n",
    "y_prob = randgbm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6172938350680545\n",
      "Recall: 0.6172938350680545\n",
      "Precision: 0.4909999886228291\n",
      "F1: 0.5181056565054468\n",
      "ROC AUC: 0.5352592299273472\n",
      "Confusion matrix:\n",
      " [[748  45   6   2   0]\n",
      " [291  23   1   2   0]\n",
      " [ 62   2   0   0   0]\n",
      " [ 61   4   0   0   0]\n",
      " [  2   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76       801\n",
      "           1       0.31      0.07      0.12       317\n",
      "           2       0.00      0.00      0.00        64\n",
      "           3       0.00      0.00      0.00        65\n",
      "           4       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.62      1249\n",
      "   macro avg       0.19      0.20      0.18      1249\n",
      "weighted avg       0.49      0.62      0.52      1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob, average = 'weighted', multi_class='ovo'))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  4.9min finished\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {'n_neighbors': range(10, 501, 10)}\n",
    "f1 = make_scorer(f1_score, average='weighted')  # for scoring param\n",
    "rand_knn_t = RandomizedSearchCV(estimator=KNeighborsClassifier(),\n",
    "                                param_distributions=param_distributions,\n",
    "                                cv=3,\n",
    "                                verbose=3,\n",
    "                                n_iter=50,\n",
    "                                n_jobs=-1,\n",
    "                                scoring=f1)\n",
    "rand_knn_t.fit(X_train_t, y_train_t)\n",
    "y_pred_t = rand_knn_t.predict(X_test_t)\n",
    "y_prob_t = rand_knn_t.predict_proba(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6036829463570856\n",
      "Recall: 0.6036829463570856\n",
      "Precision: 0.4671615367776791\n",
      "F1: 0.5033427184926162\n",
      "ROC AUC: 0.520161300171576\n",
      "Confusion matrix:\n",
      " [[730  56   1   0   0]\n",
      " [301  24   0   1   0]\n",
      " [ 60   5   0   0   0]\n",
      " [ 66   4   0   0   0]\n",
      " [  0   1   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.93      0.75       787\n",
      "           1       0.27      0.07      0.12       326\n",
      "           2       0.00      0.00      0.00        65\n",
      "           3       0.00      0.00      0.00        70\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.60      1249\n",
      "   macro avg       0.18      0.20      0.17      1249\n",
      "weighted avg       0.47      0.60      0.50      1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test_t, y_pred_t))\n",
    "print(\"Recall:\", recall_score(y_test_t, y_pred_t, average = 'weighted'))\n",
    "print(\"Precision:\", precision_score(y_test_t, y_pred_t, average = 'weighted'))\n",
    "print(\"F1:\", f1_score(y_test_t, y_pred_t, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test_t, y_prob_t, average = 'weighted', multi_class='ovo'))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_t, y_pred_t))\n",
    "print(classification_report(y_test_t, y_pred_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.7min finished\n"
     ]
    }
   ],
   "source": [
    "classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1))\n",
    "param_grid = {\n",
    "    'n_estimators': range(10, 301, 20),\n",
    "    'learning_rate': [0.1, 0.25, 0.5, 0.75, 1]\n",
    "}\n",
    "\n",
    "randdAdaBoost_t = RandomizedSearchCV(estimator=classifier,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   cv=2,\n",
    "                                   n_iter=50,\n",
    "                                   verbose=3,\n",
    "                                   scoring=f1,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "randdAdaBoost_t.fit(X_train_t, y_train_t)\n",
    "y_pred_t = randdAdaBoost_t.predict(X_test_t)\n",
    "y_prob_t = randdAdaBoost_t.predict_proba(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6236989591673339\n",
      "Recall: 0.6236989591673339\n",
      "Precision: 0.39584764585862237\n",
      "F1: 0.4843128572912598\n",
      "ROC AUC: 0.5024652256468304\n",
      "Confusion matrix:\n",
      " [[779   3   4   0   1]\n",
      " [325   0   1   0   0]\n",
      " [ 65   0   0   0   0]\n",
      " [ 70   0   0   0   0]\n",
      " [  1   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.99      0.77       787\n",
      "           1       0.00      0.00      0.00       326\n",
      "           2       0.00      0.00      0.00        65\n",
      "           3       0.00      0.00      0.00        70\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      1249\n",
      "   macro avg       0.13      0.20      0.15      1249\n",
      "weighted avg       0.40      0.62      0.48      1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test_t, y_pred_t))\n",
    "print(\"Recall:\", recall_score(y_test_t, y_pred_t, average = 'weighted'))\n",
    "print(\"Precision:\", precision_score(y_test_t, y_pred_t, average = 'weighted'))\n",
    "print(\"F1:\", f1_score(y_test_t, y_pred_t, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test_t, y_prob_t, average = 'weighted', multi_class='ovo'))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_t, y_pred_t))\n",
    "print(classification_report(y_test_t, y_pred_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  6.4min finished\n"
     ]
    }
   ],
   "source": [
    "svcclassifier = SVC(probability=True)\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4, 5, 6, 7]\n",
    "}\n",
    "\n",
    "rand_svc_t = RandomizedSearchCV(estimator=svcclassifier,\n",
    "                              param_distributions=param_grid,\n",
    "                              scoring=f1,\n",
    "                              n_jobs=-1,\n",
    "                              cv=2,\n",
    "                              verbose=1)\n",
    "\n",
    "rand_svc_t.fit(X_train_t, y_train_t)\n",
    "\n",
    "y_pred_t = rand_svc_t.predict(X_test_t)\n",
    "y_proba_t = rand_svc_t.predict_proba(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6188951160928743\n",
      "Recall: 0.6188951160928743\n",
      "Precision: 0.519177394951231\n",
      "F1: 0.5208617646432911\n",
      "ROC AUC: 0.5024652256468304\n",
      "Confusion matrix:\n",
      " [[743  29  15   0   0]\n",
      " [292  29   5   0   0]\n",
      " [ 60   4   1   0   0]\n",
      " [ 63   5   2   0   0]\n",
      " [  1   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.94      0.76       787\n",
      "           1       0.43      0.09      0.15       326\n",
      "           2       0.04      0.02      0.02        65\n",
      "           3       0.00      0.00      0.00        70\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      1249\n",
      "   macro avg       0.22      0.21      0.19      1249\n",
      "weighted avg       0.52      0.62      0.52      1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test_t, y_pred_t))\n",
    "print(\"Recall:\", recall_score(y_test_t, y_pred_t, average = 'weighted'))\n",
    "print(\"Precision:\", precision_score(y_test_t, y_pred_t, average = 'weighted'))\n",
    "print(\"F1:\", f1_score(y_test_t, y_pred_t, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test_t, y_prob_t, average = 'weighted', multi_class='ovo'))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_t, y_pred_t))\n",
    "print(classification_report(y_test_t, y_pred_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 32.4min finished\n"
     ]
    }
   ],
   "source": [
    "gbm = LGBMClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': range(10, 301, 20),\n",
    "    'learning_rate': [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "}\n",
    "randgbm_t = RandomizedSearchCV(estimator=gbm,\n",
    "                               param_distributions=param_grid,\n",
    "                               cv=2,\n",
    "                               verbose=3,\n",
    "                               n_iter=50,\n",
    "                               scoring=f1,\n",
    "                               n_jobs=-1)\n",
    "randgbm_t.fit(X_train_t, y_train_t)\n",
    "y_pred_t = randgbm_t.predict(X_test_t)\n",
    "y_prob_t = randgbm_t.predict_proba(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6060848678943155\n",
      "Recall: 0.6060848678943155\n",
      "Precision: 0.46069559315092445\n",
      "F1: 0.49275869469075384\n",
      "ROC AUC: 0.539903013435937\n",
      "Confusion matrix:\n",
      " [[745  35   4   3   0]\n",
      " [311  11   2   2   0]\n",
      " [ 62   3   0   0   0]\n",
      " [ 66   3   0   1   0]\n",
      " [  1   0   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.95      0.76       787\n",
      "           1       0.21      0.03      0.06       326\n",
      "           2       0.00      0.00      0.00        65\n",
      "           3       0.17      0.01      0.03        70\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61      1249\n",
      "   macro avg       0.20      0.20      0.17      1249\n",
      "weighted avg       0.46      0.61      0.49      1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\semav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test_t, y_pred_t))\n",
    "print(\"Recall:\", recall_score(y_test_t, y_pred_t, average = 'weighted'))\n",
    "print(\"Precision:\", precision_score(y_test_t, y_pred_t, average = 'weighted'))\n",
    "print(\"F1:\", f1_score(y_test_t, y_pred_t, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test_t, y_prob_t, average = 'weighted', multi_class='ovo'))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_t, y_pred_t))\n",
    "print(classification_report(y_test_t, y_pred_t))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Classificators_bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
